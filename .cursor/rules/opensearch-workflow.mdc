---
description: "OpenSearch search builder workflow. Triggers for: build search app, semantic search, vector search, hybrid search, OpenSearch, index setup, search architecture, large-scale search, RAG, retrieval, embeddings, knn, neural search, document search, search relevance, BM25, dense vector, sparse vector, sagemaker, bedrock"
globs: []
alwaysApply: true
---

## OpenSearch Search Builder â€” MCP Workflow

You have access to the `opensearch-orchestrator` MCP server.
Follow these phases in order using its tools:

### Phase 1: Collect Sample Document
- Call `load_sample(source_type, source_value)` first.
  - source_type: "builtin_imdb" | "local_file" | "url" | "localhost_index" | "paste"
  - source_value: path, URL, index name, or JSON content (empty string for builtin_imdb)
- The result includes `inferred_text_fields` and `text_search_required`.

### Phase 2: Gather Preferences
- Ask one preference question at a time, in this order:
  - budget (flexible / cost-sensitive)
  - performance priority (speed-first / balanced / accuracy-first)
  - query pattern (`mostly-exact` like "Carmencita 1894" / `mostly-semantic` like "early silent films about dancers" / `balanced` mix of both)
- Use the client user-input UI for each question (fixed options only, no free-text).
- If query pattern is balanced or mostly-semantic, ask deployment preference as a separate follow-up question
  (opensearch-node / sagemaker-endpoint / external-embedding-api), also via user-input UI.
- Call `set_preferences(budget, performance, query_pattern, deployment_preference)`.

### Phase 3: Plan
- Call `start_planning()` to get the initial architecture proposal.
- If `start_planning()` returns `manual_planning_required=true`, use
  `manual_planner_system_prompt` + `manual_planner_initial_input` to run planner turns with the client LLM.
- Present the proposal to the user.
- If the user has feedback, refine the proposal (with tools when available, otherwise directly with the client LLM) and repeat.
- When the user confirms:
  - tool-driven path: call `finalize_plan()` and use {solution, search_capabilities, keynote}
  - manual path: call `set_plan_from_planning_complete(planner_response)` with the finalized planner output

### Phase 4: Execute
- Call `execute_plan()` to create the index, models, pipelines, and launch the UI.
- If execution fails, the user can fix the issue (e.g., restart Docker) and you
  call `retry_execution()`.

### Post-Execution
- After successful `execute_plan()`/`retry_execution()`, explicitly tell the user
  how to access the UI using the `ui_access` URLs returned by the tool result.
- `cleanup_verification()` removes test documents when the user explicitly asks.

### Rules
- Never skip Phase 1. A sample document is mandatory before planning.
- Prefer planner tools for plan generation.
- If `manual_planning_required=true`, use the returned planner prompt/input and persist via `set_plan_from_planning_complete(...)`.
- Show the planner's proposal text to the user verbatim; do not summarize it away.
- For preference questions, ask one question per turn and use user-input UI fixed options. Accept either a number or free-text answer.
- Do not ask redundant clarification questions for items already inferred from the sample data.
